num_classes 는 input 의 num classes 가 아닌 출력 결과물의 num_classes 임.
즉 class 개수가 전체 세그멘테이션 해야하는 label 의 개수임.

각 maxpooling layer의 output들을 dict형태에 담는다.
output만 가져오는게 아니라 저런 형태로 짜여진 이유는 output과 연견된 node graph까지 함께 가져오기 위함이다.
output만 단순히 딸랑 가져오게 되면 이전 layer들과의 연결이 끊겨 학습을 할 수가 없다
라고 블로그에 설명되어 있었음

ValueError: num_samples should be a positive integer value, but got num_samples=0
x, y 겹치는 항목들을 데이터 뽑으려 했는데 x 항목을 잘못 뽑아 x, y 겹치는 항목이 없다고 나와 뽑으려는 데이터 리스트가 빈 리스트라서
데이터로더 실행할때 문제가 발생했나봄

RuntimeError: stack expects each tensor to be equal size, but got [1, 224, 246] at entry 0 and [1, 233, 224] at entry 1
transforms.Resize(size=ConstVar.RESIZE_SIZE), 이렇게 할 경우 원본 이미지가 동일한 가로 세로 길이 가지고 있을 경우 RESIZE_SIZE, RESIZE_SIZE
로 자동으로 변환 되지만 가로 세로 길이가 달랐을 경우 둘 중 하나만 RESIZE_SIZE 가 적용되는 것 같음.
따라서 size=(RESIZE_SIZE, RESIZE_SIZE) 이렇게 해주는게 안전함

RuntimeError: stack expects each tensor to be equal size, but got [1, 224, 224] at entry 0 and [3, 224, 224] at entry 3
채널 수 맞게 데이터 처리 및 정제해주기
transforms.Grayscale(num_output_channels=1) 이거로 해결

ValueError: operands could not be broadcast together with shapes (8,) (8,224,224)
뭔가 이상할때는 모델을 다른걸 써주지는 않았는지 확인해보기
나같은 경우 다른 모델 사용해서 그랬음

RuntimeError: Only Tensors created explicitly by the user (graph leaves) support the deepcopy protocol at the moment
블로그 참조 글: 가령 딥러닝 모델의 아웃풋을 copy.deepcopy()로 복사하려고 하면 다음과 같은 오류가 발생한다.
결과물 그림 출력을 하려고 test 코드에서 self.pics 에 model 의 아웃풋인 y_pred 를 담아놓는 과정 때문에 deepcopy 하는 과정에서 오류 발생
dcgan, autoencoder 에서도 그림 출력 하려고 model 결과물 담아놓았기 때문에 best model 검사할때 tester deepcopy 하는 과정에서 오류 발생했을 거임
테스트 코드에서 y_pred = self.model(x) 에 .detach() 를 붙여
y_pred = self.model(x).detach() 이렇게 했더니 해결됨
clone 은 Tensor 의 함수이기 때문에 tester 에 적용하면 Tester 객체에는 없는 함수라고 뜸.
즉 clone 은 해결 방법이 아님

메모리 오버플로우 났었음.
이유는 train, test 데이터 나누지 않고 똑같이 사용하니까 test 시에 데이터가 train 데이터랑 양이 똑같으니까 매우 많은데 거기에 결과물 그림까지 저장하려 했더니 오류났었음
그래서 8대 2 비율로 나눠주고 했더니 메모리 오버플로우 해결 되었음
